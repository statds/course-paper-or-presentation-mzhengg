{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzheng/stat3494-paper/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mzheng/stat3494-paper/data/amazon_reviews.txt', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B00LH0Y3NM</td>\n",
       "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
       "      <td>New era for batteries</td>\n",
       "      <td>Lithium batteries are something new introduced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B000I5UZ1Q</td>\n",
       "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
       "      <td>doesn't swing very well.</td>\n",
       "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>B003822IRA</td>\n",
       "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
       "      <td>Great computing!</td>\n",
       "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>B00PWSAXAM</td>\n",
       "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
       "      <td>Only use twice a week</td>\n",
       "      <td>I only use it twice a week and the results are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID       LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "0       1  __label1__       4                 N               PC  B00008NG7N   \n",
       "1       2  __label1__       4                 Y         Wireless  B00LH0Y3NM   \n",
       "2       3  __label1__       3                 N             Baby  B000I5UZ1Q   \n",
       "3       4  __label1__       4                 N  Office Products  B003822IRA   \n",
       "4       5  __label1__       4                 N           Beauty  B00PWSAXAM   \n",
       "\n",
       "                                       PRODUCT_TITLE  \\\n",
       "0        Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
       "1  Note 3 Battery : Stalion Strength Replacement ...   \n",
       "2       Fisher-Price Papasan Cradle Swing, Starlight   \n",
       "3  Casio MS-80B Standard Function Desktop Calculator   \n",
       "4  Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
       "\n",
       "               REVIEW_TITLE                                        REVIEW_TEXT  \n",
       "0                    useful  When least you think so, this product will sav...  \n",
       "1     New era for batteries  Lithium batteries are something new introduced...  \n",
       "2  doesn't swing very well.  I purchased this swing for my baby. She is 6 m...  \n",
       "3          Great computing!  I was looking for an inexpensive desk calcolat...  \n",
       "4     Only use twice a week  I only use it twice a week and the results are...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-encode 'LABEL' values\n",
    "df.loc[df[\"LABEL\"] == \"__label1__\", \"LABEL\"] = '1'\n",
    "df.loc[df[\"LABEL\"] == \"__label2__\", \"LABEL\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21000 entries, 0 to 20999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   DOC_ID             21000 non-null  int64 \n",
      " 1   LABEL              21000 non-null  object\n",
      " 2   RATING             21000 non-null  int64 \n",
      " 3   VERIFIED_PURCHASE  21000 non-null  object\n",
      " 4   PRODUCT_CATEGORY   21000 non-null  object\n",
      " 5   PRODUCT_ID         21000 non-null  object\n",
      " 6   PRODUCT_TITLE      21000 non-null  object\n",
      " 7   REVIEW_TITLE       21000 non-null  object\n",
      " 8   REVIEW_TEXT        21000 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# get information about data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL  PRODUCT_CATEGORY      \n",
       "0      Apparel                   350\n",
       "       Automotive                350\n",
       "       Baby                      350\n",
       "       Beauty                    350\n",
       "       Books                     350\n",
       "       Camera                    350\n",
       "       Electronics               350\n",
       "       Furniture                 350\n",
       "       Grocery                   350\n",
       "       Health & Personal Care    350\n",
       "       Home                      350\n",
       "       Home Entertainment        350\n",
       "       Home Improvement          350\n",
       "       Jewelry                   350\n",
       "       Kitchen                   350\n",
       "       Lawn and Garden           350\n",
       "       Luggage                   350\n",
       "       Musical Instruments       350\n",
       "       Office Products           350\n",
       "       Outdoors                  350\n",
       "       PC                        350\n",
       "       Pet Products              350\n",
       "       Shoes                     350\n",
       "       Sports                    350\n",
       "       Tools                     350\n",
       "       Toys                      350\n",
       "       Video DVD                 350\n",
       "       Video Games               350\n",
       "       Watches                   350\n",
       "       Wireless                  350\n",
       "1      Apparel                   350\n",
       "       Automotive                350\n",
       "       Baby                      350\n",
       "       Beauty                    350\n",
       "       Books                     350\n",
       "       Camera                    350\n",
       "       Electronics               350\n",
       "       Furniture                 350\n",
       "       Grocery                   350\n",
       "       Health & Personal Care    350\n",
       "       Home                      350\n",
       "       Home Entertainment        350\n",
       "       Home Improvement          350\n",
       "       Jewelry                   350\n",
       "       Kitchen                   350\n",
       "       Lawn and Garden           350\n",
       "       Luggage                   350\n",
       "       Musical Instruments       350\n",
       "       Office Products           350\n",
       "       Outdoors                  350\n",
       "       PC                        350\n",
       "       Pet Products              350\n",
       "       Shoes                     350\n",
       "       Sports                    350\n",
       "       Tools                     350\n",
       "       Toys                      350\n",
       "       Video DVD                 350\n",
       "       Video Games               350\n",
       "       Watches                   350\n",
       "       Wireless                  350\n",
       "Name: PRODUCT_CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_by_labels = df.groupby(df[\"LABEL\"]).PRODUCT_CATEGORY.value_counts()\n",
    "products_by_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL  RATING\n",
       "0      5         6151\n",
       "       4         1974\n",
       "       3          942\n",
       "       1          868\n",
       "       2          565\n",
       "1      5         6059\n",
       "       4         1999\n",
       "       3          926\n",
       "       1          889\n",
       "       2          627\n",
       "Name: RATING, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_by_labels = df.groupby(df[\"LABEL\"]).RATING.value_counts()\n",
    "ratings_by_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RATING  PRODUCT_CATEGORY  \n",
       "1       Wireless              103\n",
       "        Office Products        91\n",
       "        PC                     84\n",
       "        Lawn and Garden        77\n",
       "        Electronics            74\n",
       "                             ... \n",
       "5       Watches               375\n",
       "        Shoes                 371\n",
       "        Home Entertainment    359\n",
       "        Wireless              357\n",
       "        Furniture             342\n",
       "Name: PRODUCT_CATEGORY, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_by_ratings = df.groupby(df[\"RATING\"]).PRODUCT_CATEGORY.value_counts()\n",
    "products_by_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VERIFIED_PURCHASE  LABEL\n",
       "N                  1        7623\n",
       "                   0        1679\n",
       "Y                  0        8821\n",
       "                   1        2877\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_by_purchases = df.groupby(df[\"VERIFIED_PURCHASE\"]).LABEL.value_counts()\n",
    "labels_by_purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0    428.064571\n",
       "1    316.538857\n",
       "Name: TEXT_LENGTH, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new feature: length of review_texts\n",
    "df['TEXT_LENGTH'] = df['REVIEW_TEXT'].apply(len)\n",
    "textLengths_by_labels = df.groupby(df[\"LABEL\"]).TEXT_LENGTH.agg(lambda x: sum(x)/len(x))\n",
    "textLengths_by_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature: number of sentences in review_text\n",
    "df['NUM_SENTENCES'] = df['REVIEW_TEXT'].apply(lambda x: len(str(x).split('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mzheng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# get a list of common english words ('like', 'and', 'I')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_count(x):\n",
    "    total = 0\n",
    "    for char in x.split():\n",
    "        total += char in stop_words\n",
    "    return total\n",
    "\n",
    "# create new feature: number of stop words\n",
    "df['STOP_COUNT'] = df['REVIEW_TEXT'].apply(stop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caps_count(x):\n",
    "    total = 0\n",
    "    for char in x:\n",
    "        total += char in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    return total\n",
    "\n",
    "# create new feature: number of capital letters\n",
    "df['CAPS_COUNT'] = df['REVIEW_TEXT'].apply(caps_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "count = lambda l1, l2: sum([1 for x in l1 if x in l2])\n",
    "\n",
    "def punct_count(x):\n",
    "    return count(x, set(string.punctuation))\n",
    "\n",
    "# create new feature: number of punctuation symbols\n",
    "df['PUNCT_COUNT'] = df['REVIEW_TEXT'].apply(punct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature: number of emojis used\n",
    "df[\"EMOJIS\"] = df[\"REVIEW_TEXT\"].apply(lambda x: 1 if \";)\" in x.split() or \":)\" in x.split() or \":-)\" in x.split() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature: sentiment classifier\n",
    "\n",
    "# any rating < 3 is a negative review\n",
    "df.loc[df[\"RATING\"] < 3, \"RATING\"] = 0\n",
    "\n",
    "# a review of 3 is neutral and doesn't fall into either category\n",
    "\n",
    "# any rating > 3 is a positive review\n",
    "df.loc[df[\"RATING\"] > 3, \"RATING\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16183\n",
       "0     2949\n",
       "3     1868\n",
       "Name: RATING, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rating 1 is over-represented compared to rating 0 and rating 3 should be ignored\n",
    "df.RATING.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "      <th>TEXT_LENGTH</th>\n",
       "      <th>NUM_SENTENCES</th>\n",
       "      <th>STOP_COUNT</th>\n",
       "      <th>CAPS_COUNT</th>\n",
       "      <th>PUNCT_COUNT</th>\n",
       "      <th>EMOJIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Toys</td>\n",
       "      <td>B00M159GCK</td>\n",
       "      <td>Ginzick 4ch Rc Remote Control Speed Zoom Race ...</td>\n",
       "      <td>Wow! It's cool</td>\n",
       "      <td>My son loves this... it works awesome &amp; goes r...</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Pet Products</td>\n",
       "      <td>B0114CAWBY</td>\n",
       "      <td>★★ MASSIVE 32OZ GLUCOSAMINE★★Best Glucosamine,...</td>\n",
       "      <td>Has really helped</td>\n",
       "      <td>A great product, I totally recommend it to you...</td>\n",
       "      <td>433</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Camera</td>\n",
       "      <td>B00GXGZ6UY</td>\n",
       "      <td>HDView 2.4MP HD-AHD 1080P Outdoor Turbo Platin...</td>\n",
       "      <td>Caught a thief</td>\n",
       "      <td>Installed about 3 months, works great. It caug...</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11867</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Home</td>\n",
       "      <td>B0097GMHXG</td>\n",
       "      <td>Seville Classics WEB162 Mobile Laptop Desk Cart</td>\n",
       "      <td>Stable cart with a solid top.</td>\n",
       "      <td>This laptop cart has a one piece level top tha...</td>\n",
       "      <td>995</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12086</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B00A4B35I4</td>\n",
       "      <td>Fisher-Price Deluxe Newborn Rock 'N Play Sleep...</td>\n",
       "      <td>Great Product!</td>\n",
       "      <td>This is a must-have for those who want to have...</td>\n",
       "      <td>388</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>20961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B0069F61NU</td>\n",
       "      <td>MG Collection Lucca Designer Inspired Glamour ...</td>\n",
       "      <td>not same</td>\n",
       "      <td>the bag is not same as the picture, nothing is...</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>20967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B005B9GFUY</td>\n",
       "      <td>Fila Women's Memory Flux Slip Resistant Traini...</td>\n",
       "      <td>Too man\"ish\"</td>\n",
       "      <td>These are so manish looking I sent them back. ...</td>\n",
       "      <td>146</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>20970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B008MI08ZO</td>\n",
       "      <td>Stride Rite Star Wars Morphing Light-Up Sneake...</td>\n",
       "      <td>JUNK!</td>\n",
       "      <td>We are on our third pair in less than 2 months...</td>\n",
       "      <td>485</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>20983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B00IA6US7G</td>\n",
       "      <td>West Blvd Womens LIMA MOCCASIN Boots 3-Layer F...</td>\n",
       "      <td>Good thing they are only for one outfit to hav...</td>\n",
       "      <td>These run I would say two sizes smaller than w...</td>\n",
       "      <td>487</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>20993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B00AO3EELY</td>\n",
       "      <td>Saucony Men's Hurricane 15 Running Shoe,White/...</td>\n",
       "      <td>It is too white!</td>\n",
       "      <td>My son had ordered it but when it arrived, he ...</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6186 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DOC_ID LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "0       6596     1       1                 N             Toys  B00M159GCK   \n",
       "1       7654     1       1                 N     Pet Products  B0114CAWBY   \n",
       "2       6800     1       1                 Y           Camera  B00GXGZ6UY   \n",
       "3      11867     0       1                 Y             Home  B0097GMHXG   \n",
       "4      12086     0       1                 N             Baby  B00A4B35I4   \n",
       "...      ...   ...     ...               ...              ...         ...   \n",
       "6181   20961     0       0                 Y            Shoes  B0069F61NU   \n",
       "6182   20967     0       0                 Y            Shoes  B005B9GFUY   \n",
       "6183   20970     0       0                 Y            Shoes  B008MI08ZO   \n",
       "6184   20983     0       0                 Y            Shoes  B00IA6US7G   \n",
       "6185   20993     0       0                 Y            Shoes  B00AO3EELY   \n",
       "\n",
       "                                          PRODUCT_TITLE  \\\n",
       "0     Ginzick 4ch Rc Remote Control Speed Zoom Race ...   \n",
       "1     ★★ MASSIVE 32OZ GLUCOSAMINE★★Best Glucosamine,...   \n",
       "2     HDView 2.4MP HD-AHD 1080P Outdoor Turbo Platin...   \n",
       "3       Seville Classics WEB162 Mobile Laptop Desk Cart   \n",
       "4     Fisher-Price Deluxe Newborn Rock 'N Play Sleep...   \n",
       "...                                                 ...   \n",
       "6181  MG Collection Lucca Designer Inspired Glamour ...   \n",
       "6182  Fila Women's Memory Flux Slip Resistant Traini...   \n",
       "6183  Stride Rite Star Wars Morphing Light-Up Sneake...   \n",
       "6184  West Blvd Womens LIMA MOCCASIN Boots 3-Layer F...   \n",
       "6185  Saucony Men's Hurricane 15 Running Shoe,White/...   \n",
       "\n",
       "                                           REVIEW_TITLE  \\\n",
       "0                                        Wow! It's cool   \n",
       "1                                     Has really helped   \n",
       "2                                        Caught a thief   \n",
       "3                         Stable cart with a solid top.   \n",
       "4                                        Great Product!   \n",
       "...                                                 ...   \n",
       "6181                                           not same   \n",
       "6182                                       Too man\"ish\"   \n",
       "6183                                              JUNK!   \n",
       "6184  Good thing they are only for one outfit to hav...   \n",
       "6185                                   It is too white!   \n",
       "\n",
       "                                            REVIEW_TEXT  TEXT_LENGTH  \\\n",
       "0     My son loves this... it works awesome & goes r...          150   \n",
       "1     A great product, I totally recommend it to you...          433   \n",
       "2     Installed about 3 months, works great. It caug...          157   \n",
       "3     This laptop cart has a one piece level top tha...          995   \n",
       "4     This is a must-have for those who want to have...          388   \n",
       "...                                                 ...          ...   \n",
       "6181  the bag is not same as the picture, nothing is...          109   \n",
       "6182  These are so manish looking I sent them back. ...          146   \n",
       "6183  We are on our third pair in less than 2 months...          485   \n",
       "6184  These run I would say two sizes smaller than w...          487   \n",
       "6185  My son had ordered it but when it arrived, he ...          135   \n",
       "\n",
       "      NUM_SENTENCES  STOP_COUNT  CAPS_COUNT  PUNCT_COUNT  EMOJIS  \n",
       "0                 6           9           3           11       0  \n",
       "1                 6          38           8           12       0  \n",
       "2                 2           9           2            4       0  \n",
       "3                11          73          14           30       0  \n",
       "4                 6          35           5           17       0  \n",
       "...             ...         ...         ...          ...     ...  \n",
       "6181              2          13           1            5       0  \n",
       "6182              4           9           5            7       0  \n",
       "6183              4          52           8            7       0  \n",
       "6184              8          41          14           16       0  \n",
       "6185              3          11           2            3       0  \n",
       "\n",
       "[6186 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with all RATING = 1\n",
    "df1 = df.loc[df['RATING'] == 1]\n",
    "\n",
    "# want to make RATING = 1 more proportional to RATING = 0 (select 20% of the data with RATING = 1)\n",
    "df2 = df1.sample(frac=0.2, replace=True)\n",
    "\n",
    "# df with all RATING = 0\n",
    "df3 = df.loc[df['RATING'] == 0]\n",
    "\n",
    "# combining df2 with df3 to make a resulting df that contains proportional amounts of RATING = 1 and RATING = 0\n",
    "df4 = pd.concat([df2, df3], ignore_index=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing data to be split into test and training sets by isolating 2 key columns\n",
    "raw_data = df4[['REVIEW_TEXT', 'RATING']]\n",
    "raw_data = [tuple(x) for x in raw_data.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process review text for model\n",
    "\n",
    "# returns a table mapping each punctuation symbol to None; for use with translate() later\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "\n",
    "def processor(text):\n",
    "    # converts a word to its base form\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # stores bigrams (a pair of consecutive words)\n",
    "    filtered_tokens = []\n",
    "\n",
    "    # contains all the base words (converted from their original words in the review text)\n",
    "    lemmatized_tokens = []\n",
    "\n",
    "    # set of stop words (commonly used english words)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    # returns a string where each character is mapped to its corresponding character in the translation table\n",
    "    text = text.translate(table)\n",
    "\n",
    "    # iterate through each word in review text\n",
    "    for word in text.split(\" \"):\n",
    "        if word not in stop_words: \n",
    "            # then, the word should be converted to its base form\n",
    "            lemmatized_tokens.append(lemmatizer.lemmatize(word.lower()))\n",
    "\n",
    "        # append the bigrams of that base word to filtered_tokens\n",
    "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature vectors (to be used with 'processsor' inside 'train_test_split')\n",
    "# feature_vector numerically quantifies the contents of review_text so that ML models can use it to make predictions\n",
    "\n",
    "# a global dictionary of features\n",
    "global_feature_dict = dict()\n",
    "\n",
    "def feature_vector(tokens):\n",
    "    # a local dictionary of features\n",
    "    local_feature_dict = dict()\n",
    "\n",
    "    # iterate through each token\n",
    "    for token in tokens:\n",
    "        if token not in global_feature_dict:\n",
    "            global_feature_dict[token] = 1\n",
    "        else:\n",
    "            global_feature_dict[token] =+ 1\n",
    "\n",
    "        if token not in local_feature_dict:\n",
    "            local_feature_dict[token] = 1\n",
    "        else:\n",
    "            local_feature_dict[token] =+ 1\n",
    "    \n",
    "    return local_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mzheng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/mzheng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def train_test_split(raw_data, p):\n",
    "    # stores training set\n",
    "    training_set = []\n",
    "\n",
    "    # stores testing set\n",
    "    testing_set = []\n",
    "\n",
    "    # number of rows in raw_data\n",
    "    all_raw_data = len(raw_data)\n",
    "\n",
    "    # number of rows in half of raw_data\n",
    "    half_raw_data = int(len(raw_data)/2)\n",
    "\n",
    "    # extra rows to split by\n",
    "    randomized_index = int((p * all_raw_data)/2)\n",
    "\n",
    "    # suppose you have 100 data values and p=0.8\n",
    "    # this for-loop selects 0-39 and 50-89 as training data\n",
    "    for (review_text, rating) in raw_data[:randomized_index] + raw_data[half_raw_data:half_raw_data + randomized_index]:\n",
    "        training_set.append((feature_vector(processor(review_text)), rating))\n",
    "\n",
    "    # this for-loop selects 40-49 and 90-100 as testing data\n",
    "    for (review_text, rating) in raw_data[randomized_index:half_raw_data] + raw_data[half_raw_data + randomized_index:]:\n",
    "        testing_set.append((feature_vector(processor(review_text)), rating))\n",
    "    \n",
    "    return training_set, testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split raw data (0.8 is training, 0.2 is testing)\n",
    "training_set, testing_set = train_test_split(raw_data, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier\n",
    "# training set is a list of (feature vector, label) where each 'feature vector' is a dict mapping strings to a number\n",
    "def classifier(training_set):\n",
    "    # pipeline containing the Linear Support Vector Classifier (SVM) from sklearn\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(training_set) # trains the SVM on training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts labels using a trained classifier\n",
    "def predict(testing_set, classifier):\n",
    "    # for each 'review_text' in testing_set, map the corresponding prediction made by the classifer to it\n",
    "    return classifier.classify_many(map(lambda x: x[0], testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzheng/stat3494-paper/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train the classifier\n",
    "classifier = classifier(training_set)\n",
    "\n",
    "# make predictions using the trained classifier\n",
    "predictions = predict(testing_set, classifier)\n",
    "\n",
    "# get true labels of test data\n",
    "# for each 'rating' in testing_set, map it to a list\n",
    "true_labels = list(map(lambda x: x[1], testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8618739903069467\n",
      "Precision:  0.8620866149957174\n",
      "Recall:  0.8618739903069467\n",
      "F-score:  0.8618537097229935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy of model on test_data\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# precision, recall, and fscore on test_data\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F-score: \", fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f25d820e0f71bc755cc3fbf69492fdabc74f54a634853f0628eb6bd9e70299cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
