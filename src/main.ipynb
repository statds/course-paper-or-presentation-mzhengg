{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ingesting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mzheng/stat3494w-paper/data/amazon_reviews.txt', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B00LH0Y3NM</td>\n",
       "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
       "      <td>New era for batteries</td>\n",
       "      <td>Lithium batteries are something new introduced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B000I5UZ1Q</td>\n",
       "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
       "      <td>doesn't swing very well.</td>\n",
       "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>B003822IRA</td>\n",
       "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
       "      <td>Great computing!</td>\n",
       "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>B00PWSAXAM</td>\n",
       "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
       "      <td>Only use twice a week</td>\n",
       "      <td>I only use it twice a week and the results are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID       LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "0       1  __label1__       4                 N               PC  B00008NG7N   \n",
       "1       2  __label1__       4                 Y         Wireless  B00LH0Y3NM   \n",
       "2       3  __label1__       3                 N             Baby  B000I5UZ1Q   \n",
       "3       4  __label1__       4                 N  Office Products  B003822IRA   \n",
       "4       5  __label1__       4                 N           Beauty  B00PWSAXAM   \n",
       "\n",
       "                                       PRODUCT_TITLE  \\\n",
       "0        Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
       "1  Note 3 Battery : Stalion Strength Replacement ...   \n",
       "2       Fisher-Price Papasan Cradle Swing, Starlight   \n",
       "3  Casio MS-80B Standard Function Desktop Calculator   \n",
       "4  Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
       "\n",
       "               REVIEW_TITLE                                        REVIEW_TEXT  \n",
       "0                    useful  When least you think so, this product will sav...  \n",
       "1     New era for batteries  Lithium batteries are something new introduced...  \n",
       "2  doesn't swing very well.  I purchased this swing for my baby. She is 6 m...  \n",
       "3          Great computing!  I was looking for an inexpensive desk calcolat...  \n",
       "4     Only use twice a week  I only use it twice a week and the results are...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-encode 'LABEL' values\n",
    "df.loc[df[\"LABEL\"] == \"__label1__\", \"LABEL\"] = '1' # these are fake reviews\n",
    "df.loc[df[\"LABEL\"] == \"__label2__\", \"LABEL\"] = '0' # these are real reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21000 entries, 0 to 20999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   DOC_ID             21000 non-null  int64 \n",
      " 1   LABEL              21000 non-null  object\n",
      " 2   RATING             21000 non-null  int64 \n",
      " 3   VERIFIED_PURCHASE  21000 non-null  object\n",
      " 4   PRODUCT_CATEGORY   21000 non-null  object\n",
      " 5   PRODUCT_ID         21000 non-null  object\n",
      " 6   PRODUCT_TITLE      21000 non-null  object\n",
      " 7   REVIEW_TITLE       21000 non-null  object\n",
      " 8   REVIEW_TEXT        21000 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# get information about data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL  PRODUCT_CATEGORY      \n",
       "0      Apparel                   350\n",
       "       Automotive                350\n",
       "       Baby                      350\n",
       "       Beauty                    350\n",
       "       Books                     350\n",
       "       Camera                    350\n",
       "       Electronics               350\n",
       "       Furniture                 350\n",
       "       Grocery                   350\n",
       "       Health & Personal Care    350\n",
       "       Home                      350\n",
       "       Home Entertainment        350\n",
       "       Home Improvement          350\n",
       "       Jewelry                   350\n",
       "       Kitchen                   350\n",
       "       Lawn and Garden           350\n",
       "       Luggage                   350\n",
       "       Musical Instruments       350\n",
       "       Office Products           350\n",
       "       Outdoors                  350\n",
       "       PC                        350\n",
       "       Pet Products              350\n",
       "       Shoes                     350\n",
       "       Sports                    350\n",
       "       Tools                     350\n",
       "       Toys                      350\n",
       "       Video DVD                 350\n",
       "       Video Games               350\n",
       "       Watches                   350\n",
       "       Wireless                  350\n",
       "1      Apparel                   350\n",
       "       Automotive                350\n",
       "       Baby                      350\n",
       "       Beauty                    350\n",
       "       Books                     350\n",
       "       Camera                    350\n",
       "       Electronics               350\n",
       "       Furniture                 350\n",
       "       Grocery                   350\n",
       "       Health & Personal Care    350\n",
       "       Home                      350\n",
       "       Home Entertainment        350\n",
       "       Home Improvement          350\n",
       "       Jewelry                   350\n",
       "       Kitchen                   350\n",
       "       Lawn and Garden           350\n",
       "       Luggage                   350\n",
       "       Musical Instruments       350\n",
       "       Office Products           350\n",
       "       Outdoors                  350\n",
       "       PC                        350\n",
       "       Pet Products              350\n",
       "       Shoes                     350\n",
       "       Sports                    350\n",
       "       Tools                     350\n",
       "       Toys                      350\n",
       "       Video DVD                 350\n",
       "       Video Games               350\n",
       "       Watches                   350\n",
       "       Wireless                  350\n",
       "Name: PRODUCT_CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_by_labels = df.groupby(df[\"LABEL\"]).PRODUCT_CATEGORY.value_counts()\n",
    "products_by_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL  RATING\n",
       "0      5         6151\n",
       "       4         1974\n",
       "       3          942\n",
       "       1          868\n",
       "       2          565\n",
       "1      5         6059\n",
       "       4         1999\n",
       "       3          926\n",
       "       1          889\n",
       "       2          627\n",
       "Name: RATING, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_by_labels = df.groupby(df[\"LABEL\"]).RATING.value_counts()\n",
    "ratings_by_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL  VERIFIED_PURCHASE\n",
       "0      Y                    8821\n",
       "       N                    1679\n",
       "1      N                    7623\n",
       "       Y                    2877\n",
       "Name: VERIFIED_PURCHASE, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_by_ratings = df.groupby(df[\"LABEL\"]).VERIFIED_PURCHASE.value_counts()\n",
    "products_by_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature: sentiment classifier\n",
    "\n",
    "# any rating < 3 is a negative review\n",
    "df.loc[df[\"RATING\"] < 3, \"RATING\"] = 0\n",
    "\n",
    "# a review of 3 is neutral and doesn't fall into either category\n",
    "\n",
    "# any rating > 3 is a positive review\n",
    "df.loc[df[\"RATING\"] > 3, \"RATING\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16183\n",
       "0     2949\n",
       "3     1868\n",
       "Name: RATING, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rating 1 is over-represented compared to rating 0 and rating 3 should be ignored\n",
    "df.RATING.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15622</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pet Products</td>\n",
       "      <td>B00K0E8YEU</td>\n",
       "      <td>Eagle Pack Natural Dry Small Breed Dog Food, C...</td>\n",
       "      <td>Looked up reviews that showed this dog had les...</td>\n",
       "      <td>Looked up reviews that showed this dog had les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Lawn and Garden</td>\n",
       "      <td>B00DNIP0N8</td>\n",
       "      <td>Thunder (TM) Sunmax 8-Inch White Air Coolable ...</td>\n",
       "      <td>great big@$/#! hood</td>\n",
       "      <td>I am very impressed with the hood. High qualit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>B00JH9XSZE</td>\n",
       "      <td>Gourmet Gold Ganoderma Latte Coffee, The Herb ...</td>\n",
       "      <td>Really tasty and relaxing.</td>\n",
       "      <td>I've always loved coffee but hated any side ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16289</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B007M7E6ZE</td>\n",
       "      <td>Aimo Wireless SAMU380PCLP005 Rubber Essentials...</td>\n",
       "      <td>Pink phone cover</td>\n",
       "      <td>I love the case for my Samsung phone. I droppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20038</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Luggage</td>\n",
       "      <td>B001CZT4L8</td>\n",
       "      <td>Travelon Set of 2 Inflatable Hangers, White, O...</td>\n",
       "      <td>No Pointy Shoulders!</td>\n",
       "      <td>Took 4 on a long trip and used them every few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>20961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B0069F61NU</td>\n",
       "      <td>MG Collection Lucca Designer Inspired Glamour ...</td>\n",
       "      <td>not same</td>\n",
       "      <td>the bag is not same as the picture, nothing is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>20967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B005B9GFUY</td>\n",
       "      <td>Fila Women's Memory Flux Slip Resistant Traini...</td>\n",
       "      <td>Too man\"ish\"</td>\n",
       "      <td>These are so manish looking I sent them back. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>20970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B008MI08ZO</td>\n",
       "      <td>Stride Rite Star Wars Morphing Light-Up Sneake...</td>\n",
       "      <td>JUNK!</td>\n",
       "      <td>We are on our third pair in less than 2 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>20983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B00IA6US7G</td>\n",
       "      <td>West Blvd Womens LIMA MOCCASIN Boots 3-Layer F...</td>\n",
       "      <td>Good thing they are only for one outfit to hav...</td>\n",
       "      <td>These run I would say two sizes smaller than w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>20993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>B00AO3EELY</td>\n",
       "      <td>Saucony Men's Hurricane 15 Running Shoe,White/...</td>\n",
       "      <td>It is too white!</td>\n",
       "      <td>My son had ordered it but when it arrived, he ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6186 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DOC_ID LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "0      15622     0       1                 Y     Pet Products  B00K0E8YEU   \n",
       "1      15678     0       1                 Y  Lawn and Garden  B00DNIP0N8   \n",
       "2       6479     1       1                 Y          Grocery  B00JH9XSZE   \n",
       "3      16289     0       1                 Y         Wireless  B007M7E6ZE   \n",
       "4      20038     0       1                 Y          Luggage  B001CZT4L8   \n",
       "...      ...   ...     ...               ...              ...         ...   \n",
       "6181   20961     0       0                 Y            Shoes  B0069F61NU   \n",
       "6182   20967     0       0                 Y            Shoes  B005B9GFUY   \n",
       "6183   20970     0       0                 Y            Shoes  B008MI08ZO   \n",
       "6184   20983     0       0                 Y            Shoes  B00IA6US7G   \n",
       "6185   20993     0       0                 Y            Shoes  B00AO3EELY   \n",
       "\n",
       "                                          PRODUCT_TITLE  \\\n",
       "0     Eagle Pack Natural Dry Small Breed Dog Food, C...   \n",
       "1     Thunder (TM) Sunmax 8-Inch White Air Coolable ...   \n",
       "2     Gourmet Gold Ganoderma Latte Coffee, The Herb ...   \n",
       "3     Aimo Wireless SAMU380PCLP005 Rubber Essentials...   \n",
       "4     Travelon Set of 2 Inflatable Hangers, White, O...   \n",
       "...                                                 ...   \n",
       "6181  MG Collection Lucca Designer Inspired Glamour ...   \n",
       "6182  Fila Women's Memory Flux Slip Resistant Traini...   \n",
       "6183  Stride Rite Star Wars Morphing Light-Up Sneake...   \n",
       "6184  West Blvd Womens LIMA MOCCASIN Boots 3-Layer F...   \n",
       "6185  Saucony Men's Hurricane 15 Running Shoe,White/...   \n",
       "\n",
       "                                           REVIEW_TITLE  \\\n",
       "0     Looked up reviews that showed this dog had les...   \n",
       "1                                   great big@$/#! hood   \n",
       "2                            Really tasty and relaxing.   \n",
       "3                                      Pink phone cover   \n",
       "4                                  No Pointy Shoulders!   \n",
       "...                                                 ...   \n",
       "6181                                           not same   \n",
       "6182                                       Too man\"ish\"   \n",
       "6183                                              JUNK!   \n",
       "6184  Good thing they are only for one outfit to hav...   \n",
       "6185                                   It is too white!   \n",
       "\n",
       "                                            REVIEW_TEXT  \n",
       "0     Looked up reviews that showed this dog had les...  \n",
       "1     I am very impressed with the hood. High qualit...  \n",
       "2     I've always loved coffee but hated any side ef...  \n",
       "3     I love the case for my Samsung phone. I droppe...  \n",
       "4     Took 4 on a long trip and used them every few ...  \n",
       "...                                                 ...  \n",
       "6181  the bag is not same as the picture, nothing is...  \n",
       "6182  These are so manish looking I sent them back. ...  \n",
       "6183  We are on our third pair in less than 2 months...  \n",
       "6184  These run I would say two sizes smaller than w...  \n",
       "6185  My son had ordered it but when it arrived, he ...  \n",
       "\n",
       "[6186 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with all RATING = 1\n",
    "df1 = df.loc[df['RATING'] == 1]\n",
    "\n",
    "# want to make RATING = 1 more proportional to RATING = 0 (select 20% of the data with RATING = 1)\n",
    "df2 = df1.sample(frac=0.2, replace=True)\n",
    "\n",
    "# df with all RATING = 0\n",
    "df3 = df.loc[df['RATING'] == 0]\n",
    "\n",
    "# combining df2 with df3 to make a resulting df that contains proportional amounts of RATING = 1 and RATING = 0\n",
    "df4 = pd.concat([df2, df3], ignore_index=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing data to be split into test and training sets by isolating the columns of interest\n",
    "raw_data = df4[['RATING', 'VERIFIED_PURCHASE', 'PRODUCT_CATEGORY', 'REVIEW_TEXT', 'LABEL']]\n",
    "raw_data = [tuple(x) for x in raw_data.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mzheng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# get a list of common english words ('like', 'and', 'I')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process review text for model\n",
    "import string\n",
    "\n",
    "# returns a table mapping each punctuation symbol to None; for use with translate() later\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "\n",
    "def processor(text):\n",
    "    # converts a word to its base form\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # stores bigrams (a pair of consecutive words)\n",
    "    filtered_tokens = []\n",
    "\n",
    "    # contains all the base words (converted from their original words in the review text)\n",
    "    lemmatized_tokens = []\n",
    "\n",
    "    # set of stop words (commonly used english words)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    # returns a string where each character is mapped to its corresponding character in the translation table\n",
    "    text = text.translate(table)\n",
    "\n",
    "    # iterate through each word in review text\n",
    "    for word in text.split(\" \"):\n",
    "        if word not in stop_words: \n",
    "            # then, the word should be converted to its base form\n",
    "            lemmatized_tokens.append(lemmatizer.lemmatize(word.lower()))\n",
    "\n",
    "        # append the bigrams of that base word to filtered_tokens\n",
    "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature vectors (must use 'processsor' on review_text before inputting)\n",
    "# feature_vector numerically quantifies the contents of features so that ML models can use it to make predictions\n",
    "\n",
    "# NOTE: each feature to be used in the 'classifier' must be inputted into the feature vector\n",
    "\n",
    "def feature_vector(rating, verified_purchase, product_category, review_text):\n",
    "    # dictionary of features\n",
    "    feature_dict = dict()\n",
    "\n",
    "    # rating feature\n",
    "    feature_dict[\"R\"] = rating\n",
    "\n",
    "    # verified_purchase feature\n",
    "    if verified_purchase == \"Y\":\n",
    "        feature_dict[\"VP\"] = 1\n",
    "    else:\n",
    "        feature_dict[\"VP\"] = 0\n",
    "\n",
    "    # product_category feature\n",
    "    if product_category not in feature_dict:\n",
    "        feature_dict[product_category] = 1\n",
    "    else:\n",
    "        feature_dict[product_category] =+ 1\n",
    "\n",
    "    # review_text feature\n",
    "    for text in review_text:\n",
    "        if text not in feature_dict:\n",
    "            feature_dict[text] = 1\n",
    "        else:\n",
    "            feature_dict[text] =+ 1\n",
    "    \n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mzheng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/mzheng/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def train_test_split(raw_data, p):\n",
    "    # stores training set\n",
    "    training_set = []\n",
    "\n",
    "    # stores testing set\n",
    "    testing_set = []\n",
    "\n",
    "    # number of rows in raw_data\n",
    "    all_raw_data = len(raw_data)\n",
    "\n",
    "    # number of rows in half of raw_data\n",
    "    half_raw_data = int(len(raw_data)/2)\n",
    "\n",
    "    # extra rows to split by\n",
    "    randomized_index = int((p * all_raw_data)/2)\n",
    "\n",
    "    # suppose you have 100 data values and p=0.8\n",
    "    # this for-loop selects 0-39 and 50-89 as training data\n",
    "    for (rating, verified_purchase, product_category, review_text, label) in raw_data[:randomized_index] + raw_data[half_raw_data:half_raw_data + randomized_index]:\n",
    "        training_set.append((feature_vector(rating, verified_purchase, product_category, processor(review_text)), label))\n",
    "\n",
    "    # this for-loop selects 40-49 and 90-100 as testing data\n",
    "    for (rating, verified_purchase, product_category, review_text, label) in raw_data[randomized_index:half_raw_data] + raw_data[half_raw_data + randomized_index:]:\n",
    "        testing_set.append((feature_vector(rating, verified_purchase, product_category, processor(review_text)), label))\n",
    "    \n",
    "    return training_set, testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split raw data (0.8 is training, 0.2 is testing)\n",
    "training_set, testing_set = train_test_split(raw_data, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier\n",
    "# training set is a list of (feature vector, label)\n",
    "def classifier(training_set):\n",
    "    # pipeline containing the Linear Support Vector Classifier (SVM) from sklearn\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(training_set) # trains the SVM on training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts labels on testing_set using a trained classifier\n",
    "def predict(testing_set, classifier):\n",
    "    # for each feature vector in testing_set, map the corresponding prediction made by the classifer to a list and return it\n",
    "    return classifier.classify_many(map(lambda x: x[0], testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train the classifier\n",
    "classifier = classifier(training_set)\n",
    "\n",
    "# make predictions using the trained classifier\n",
    "predictions = predict(testing_set, classifier)\n",
    "\n",
    "# get true labels of test data\n",
    "# for each 'label' in testing_set, map it to a list\n",
    "true_labels = list(map(lambda x: x[1], testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7600969305331179\n",
      "Precision:  0.7101330732251098\n",
      "Recall:  0.7632348833961737\n",
      "F-score:  0.720296221915401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy of classifier on test data\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# precision, recall, and fscore on test data\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F-score: \", fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[704, 226],\n",
       "       [ 71, 237]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
